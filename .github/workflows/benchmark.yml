name: Benchmark Regression Check

on:
  pull_request:
    branches:
      - main
  push:
    branches:
      - main

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

# Configurable thresholds. Adjust these defaults as the project matures.
env:
  # benchstat reports "~" (no change), "+" (regression), or "-" (improvement).
  # This threshold is for documentation; benchstat uses statistical significance
  # with the given sample count. With -count=5 and alpha=0.05 it filters noise.
  BENCH_COUNT: "5"
  GO_VERSION: "1.22"

permissions:
  contents: read
  pull-requests: write

jobs:
  benchmark:
    name: Benchmark Comparison
    runs-on: ubuntu-latest
    steps:
      - name: Check out PR branch
        uses: actions/checkout@v4
        with:
          path: pr

      - name: Check out base branch
        uses: actions/checkout@v4
        with:
          ref: ${{ github.event.pull_request.base.sha || github.event.before || 'main' }}
          path: base
        # On push to main, github.event.before is the previous commit.
        # On the very first push (repo init), this may fail — that's OK, we
        # skip comparison below when base results are missing.
        continue-on-error: true

      - name: Set up Go
        uses: actions/setup-go@v5
        with:
          go-version: ${{ env.GO_VERSION }}
          cache: true
          cache-dependency-path: pr/go.sum

      - name: Install benchstat
        run: go install golang.org/x/perf/cmd/benchstat@latest

      - name: Run benchmarks (base)
        id: bench-base
        working-directory: base
        run: |
          if [ ! -f go.mod ]; then
            echo "skip=true" >> "$GITHUB_OUTPUT"
            echo "::warning::Base checkout missing or empty — skipping comparison."
            exit 0
          fi
          go test -bench=. -benchmem -benchtime=100ms -count=${{ env.BENCH_COUNT }} -run='^$' -timeout=10m ./... \
            | tee "$RUNNER_TEMP/bench-base.txt"
          echo "skip=false" >> "$GITHUB_OUTPUT"
        continue-on-error: true

      - name: Run benchmarks (PR)
        working-directory: pr
        run: |
          go test -bench=. -benchmem -benchtime=100ms -count=${{ env.BENCH_COUNT }} -run='^$' -timeout=10m ./... \
            | tee "$RUNNER_TEMP/bench-pr.txt"

      - name: Compare with benchstat
        id: benchstat
        run: |
          if [ "${{ steps.bench-base.outputs.skip }}" = "true" ] || [ ! -s "$RUNNER_TEMP/bench-base.txt" ]; then
            echo "No base benchmark results available — showing PR results only."
            echo "has_comparison=false" >> "$GITHUB_OUTPUT"

            {
              echo 'result<<BENCHSTAT_EOF'
              echo '## Benchmark Results (no base branch to compare)'
              echo ''
              echo 'This is the first run or the base branch had no benchmarks to compare against.'
              echo ''
              echo '```'
              cat "$RUNNER_TEMP/bench-pr.txt"
              echo '```'
              echo 'BENCHSTAT_EOF'
            } >> "$GITHUB_OUTPUT"
            exit 0
          fi

          echo "has_comparison=true" >> "$GITHUB_OUTPUT"

          # Run benchstat; it exits 0 regardless of regressions.
          benchstat base="$RUNNER_TEMP/bench-base.txt" pr="$RUNNER_TEMP/bench-pr.txt" \
            > "$RUNNER_TEMP/benchstat.txt" 2>&1 || true

          # Build the output for PR comment.
          {
            echo 'result<<BENCHSTAT_EOF'
            echo '## Benchmark Comparison (base vs PR)'
            echo ''
            echo '<details>'
            echo '<summary>Click to expand benchstat output</summary>'
            echo ''
            echo '```'
            cat "$RUNNER_TEMP/benchstat.txt"
            echo '```'
            echo ''
            echo '</details>'
            echo ''
            echo '_Generated by the benchmark workflow. Regressions marked with `+` are flagged as warnings but do not block the PR._'
            echo 'BENCHSTAT_EOF'
          } >> "$GITHUB_OUTPUT"

          # Check for statistically significant regressions.
          # benchstat shows "+" for regressions that pass the significance test.
          # We look for lines with a "+" that are NOT the header line.
          if grep -E '^\S.*\+$' "$RUNNER_TEMP/benchstat.txt" | grep -qv '^name'; then
            echo "has_regression=true" >> "$GITHUB_OUTPUT"
            echo "::warning::Benchstat detected statistically significant regressions. See the PR comment for details."
          else
            echo "has_regression=false" >> "$GITHUB_OUTPUT"
          fi

      - name: Post PR comment
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        env:
          BENCH_RESULT: ${{ steps.benchstat.outputs.result }}
        with:
          # Use the default GITHUB_TOKEN. For PRs from forks this token has
          # read-only permissions and the comment will be silently skipped.
          script: |
            const body = process.env.BENCH_RESULT;
            const marker = '<!-- benchmark-comparison-comment -->';
            const fullBody = marker + '\n' + body;

            // Try to find and update an existing comment from a previous run.
            let existingComment = null;
            try {
              const { data: comments } = await github.rest.issues.listComments({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                per_page: 100,
              });
              existingComment = comments.find(c => c.body.includes(marker));
            } catch (e) {
              core.warning(`Could not list PR comments: ${e.message}`);
            }

            try {
              if (existingComment) {
                await github.rest.issues.updateComment({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  comment_id: existingComment.id,
                  body: fullBody,
                });
                core.info(`Updated existing benchmark comment ${existingComment.id}`);
              } else {
                await github.rest.issues.createComment({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  issue_number: context.issue.number,
                  body: fullBody,
                });
                core.info('Created new benchmark comment');
              }
            } catch (e) {
              // Fork PRs may lack write permissions — warn but don't fail.
              core.warning(`Could not post PR comment: ${e.message}. This is expected for PRs from forks.`);
            }

      - name: Annotate regressions
        if: steps.benchstat.outputs.has_regression == 'true'
        run: |
          echo "::warning::Benchmark regressions detected. Review the benchstat comparison above."
          # Informational only — exit 0 so the workflow does not block the PR.
          # To make this a hard gate, change to: exit 1
          exit 0
